# The main entry point of your workflow for smallRNA Pipeline
# After configuring, running snakemake -n in a clone of this repository should
# successfully execute a dry-run of the workflow.

import pandas as pd
from snakemake.utils import validate, min_version


##### set minimum snakemake version #####
min_version("7.8.3")


##### load config and sample sheets #####
configfile: "config/config.yaml"


validate(config, schema="schemas/config.schema.yaml")

samples = pd.read_table(config["samples"]).set_index("sample_name", drop=False)
validate(samples, schema="schemas/samples.schema.yaml")

units = pd.read_table(config["units"], dtype=str).set_index(
    ["sample_name", "unit_name"], drop=False
)
units.index = units.index.set_levels(
    [i.astype(str) for i in units.index.levels]
)  # enforce str in index
validate(units, schema="schemas/units.schema.yaml")

exogenous_sorted_bam_files = []
for unit in units.itertuples():
    sample_info = samples.loc[unit.sample_name]
    exogenous_sorted_bam_files.append(
        f"results/alignments/{sample_info.exogenous_rna}/sorted/{unit.sample_name}_{unit.unit_name}.bam",
    )


##### target rules #####
rule all:
    input:
        expand(
            "results/qc/multiqc_{genome}.html",
            genome=(
                "library",
                "exogenous_rna",
                "Homo_sapiens.GRCh38.dna.primary_assembly",
                "unmapped",
            ),
        ),
        expand(
            "results/alignments/exogenous_rna/bedpe/{sample}_{unit}.bedpe",
            sample=units.sample_name,
            unit=units.unit_name,
        ),
        expand(
            "data/references/{genome}.fa.fai",
            genome=("mastermix1", "mastermix2", "Homo_sapiens.GRCh38.dna.primary_assembly"),
        ),


rule all_trimming:
    input:
        expand(
            "results/trimmed/{sample}_{unit}.{read}.fastq.gz",
            sample=units.sample_name,
            unit=units.unit_name,
            read=["1", "2"],
        ),


rule all_mapping:
    input:
        expand(
            "results/alignments/{genome}/sorted/{sample}_{unit}.bam",
            sample=units.sample_name,
            unit=units.unit_name,
            genome=("Homo_sapiens.GRCh38.dna.primary_assembly", "exogenous_rna"),
        ),


rule all_multiqc:
    input:
        expand(
            "results/qc/multiqc_{genome}.html",
            genome=(
                "library",
                "exogenous_rna",
                "Homo_sapiens.GRCh38.dna.primary_assembly",
                "unmapped",
            ),
        ),


rule all_bedpe:
    input:
        expand(
            "results/alignments/exogenous_rna/bedpe/{sample}_{unit}.bedpe",
            sample=units.sample_name,
            unit=units.unit_name,
        ),


rule all_riboswitch:
    input:
        expand(
            "results/alignments/exogenous_rna/riboswitch/{sample}_{unit}.{read}.collapsed.fq",
            sample=units.sample_name,
            unit=units.unit_name,
            read=["1", "2"],
        ),
        expand(
            "results/alignments/exogenous_rna/riboswitch/{sample}_{unit}.brc.tsv",
            sample=units.sample_name,
            unit=units.unit_name,
        ),
        expand(
            "results/alignments/exogenous_rna/cross_alignment_check/sorted/{sample}_{unit}_to_{genome}.bam.bai",
            sample=units.sample_name,
            unit=units.unit_name,
            genome=["PJY103", "PJY300"],
        ),


##### setup container #####


# this container defines the underlying OS for each job when using the workflow
# with --use-conda --use-singularity
# container: "docker://continuumio/miniconda3"


##### setup report #####


report: "report/workflow.rst"


##### load rules #####


include: "rules/common.smk"
include: "rules/genome.smk"
include: "rules/trimming.smk"
include: "rules/mapping.smk"
include: "rules/quality_control.smk"
include: "rules/alignment_reporting.smk"
include: "rules/query_riboswitch.smk"
